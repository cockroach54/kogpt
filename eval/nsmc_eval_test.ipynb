{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee22d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shna94/naver_databox_test_bed/llama/alpaca/stanford_alpaca/alpaca_env/lib64/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import peft\n",
    "import torch\n",
    "import transformers\n",
    "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, LoraConfig, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c84873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, pre_trained_state_path):\n",
    "    load_state = torch.load(pre_trained_state_path)\n",
    "    model.load_state_dict(load_state)\n",
    "    \n",
    "    return model, load_state\n",
    "\n",
    "\n",
    "def check_param(model, load_state):\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.equal(load_state[name.replace('.default', '')]):\n",
    "            print(name + 'is not equal')\n",
    "\n",
    "\n",
    "# DEVICE = \"cuda\"\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb744dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        \"kakaobrain/kogpt\",\n",
    "        revision=\"KoGPT6B-ryan1.5b-float16\",  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "        bos_token=\"[BOS]\",\n",
    "        eos_token=\"[EOS]\",\n",
    "        unk_token=\"[UNK]\",\n",
    "        pad_token=\"[PAD]\",\n",
    "        mask_token=\"[MASK]\",\n",
    "        model_max_length=512\n",
    "#         cache_dir=training_args.cache_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513b2fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:10<00:00,  5.46s/it]\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    '/ailab/share/kogpt/kogpt-ft-3',\n",
    "    revision=\"KoGPT6B-ryan1.5b-float16\",  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    # torch_dtype=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb68aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from random import sample\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93914930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED_NUM = None\n",
    "SEED_NUM = 1234\n",
    "np.random.seed(SEED_NUM)\n",
    "random.seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "488c6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_IN_PATH = '/home/shna94/naver_databox_test_bed/llama/alpaca/KoAlpaca/data_in/KOR'\n",
    "DATA_OUT_PATH = '/home/shna94/naver_databox_test_bed/llama/alpaca/KoAlpaca/data_out/KOR'\n",
    "\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, 'naver_movie', 'ratings_train.txt')\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, 'naver_movie', 'ratings_test.txt')\n",
    "\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "train_data = train_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4152725d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 positive 라벨:  긍정\n",
      "데이터 negative 라벨:  부정\n",
      "\n",
      "학습 예시 케이스 구조:  문장: 오늘 기분이 좋아\n",
      "감정: 긍정\n",
      "\n",
      "\n",
      "모델 최대 토큰 길이:  2048\n"
     ]
    }
   ],
   "source": [
    "print('데이터 positive 라벨: ', '긍정')\n",
    "print('데이터 negative 라벨: ', '부정')\n",
    "print('\\n학습 예시 케이스 구조: ', '문장: 오늘 기분이 좋아\\n감정: 긍정\\n')\n",
    "print('\\n모델 최대 토큰 길이: ', model.config.max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c0345e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 149995/149995 [00:18<00:00, 8321.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few shot 케이스 토큰 평균 길이:  18.40927364245475\n",
      "Few shot 케이스 토큰 최대 길이:  146\n",
      "Few shot 케이스 토큰 길이 표준편차:  15.227606399857397\n",
      "Few shot 케이스 토큰 길이 80 퍼센타일:  25.0\n"
     ]
    }
   ],
   "source": [
    "sent_lens = [len(tokenizer(s).input_ids) for s in tqdm(train_data['document'])]\n",
    "\n",
    "print('Few shot 케이스 토큰 평균 길이: ', np.mean(sent_lens))\n",
    "print('Few shot 케이스 토큰 최대 길이: ', np.max(sent_lens))\n",
    "print('Few shot 케이스 토큰 길이 표준편차: ',np.std(sent_lens))\n",
    "print('Few shot 케이스 토큰 길이 80 퍼센타일: ',np.percentile(sent_lens, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd739255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 149995/149995 [00:17<00:00, 8638.53it/s]\n"
     ]
    }
   ],
   "source": [
    "train_fewshot_data = []\n",
    "\n",
    "for train_sent, train_label in tqdm(train_data[['document', 'label']].values):\n",
    "    tokens = tokenizer(train_sent).input_ids\n",
    "\n",
    "    if len(tokens) <= 25:\n",
    "        train_fewshot_data.append((train_sent, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe1519e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_TEST_PATH, header=0, delimiter='\\t', quoting=3)\n",
    "test_data = test_data.dropna()\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac2c8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Dataset\n",
    "# sample_size = len(test_data)\n",
    "\n",
    "# Sampled Dataset\n",
    "# sample_size = 500\n",
    "sample_size = 10\n",
    "\n",
    "train_fewshot_samples = []\n",
    "\n",
    "for _ in range(sample_size):\n",
    "    fewshot_examples = sample(train_fewshot_data, 10)\n",
    "    train_fewshot_samples.append(fewshot_examples)\n",
    "\n",
    "if sample_size < len(test_data['id']):\n",
    "    test_data = test_data.sample(sample_size, random_state=SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68923cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문장: 당시엔 왜그렇게 웃겼는지ㅋㅋㅋㅋㅋ 어쨌든 점ㅋㅋㅋㅋ\n",
      "감정: 긍정\n",
      "문장: 대박이요김정은언니정준호 오빠김흥수오빠너무 너무 좋아요\n",
      "감정: 긍정\n",
      "문장: 한번만 봐준다는 의미해서 점준다\n",
      "감정: 부정\n",
      "문장: 조카랑 보기 좋았던따뜻한 애니였어여\n",
      "감정: 긍정\n",
      "문장: 이게 년도 영화라니충격 이 영화 보고나니 금욕주의자가 될것 같다\n",
      "감정: 긍정\n",
      "문장: 진짜 개 노잼 뭘 말하는지 모르겠다\n",
      "감정: 부정\n",
      "문장: 야하기만한 영화는 아닌듯\n",
      "감정: 긍정\n",
      "문장: 해학을 알면보인다\n",
      "감정: 긍정\n",
      "문장: 점을 주고싶은 마음\n",
      "감정: 부정\n",
      "문장: 원작의 긴장감을 제대로 살려내지못했다\n",
      "감정: 부정\n"
     ]
    }
   ],
   "source": [
    "def build_prompt_text(sent):\n",
    "    return \"\\n\\n문장: \" + sent + '\\n감정:'\n",
    "\n",
    "def clean_text(sent):\n",
    "    sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", sent)\n",
    "    return sent_clean\n",
    "\n",
    "prompt_text = ''\n",
    "for example_text, example_label in train_fewshot_samples[i]:\n",
    "    cleaned_example_text = clean_text(example_text)\n",
    "    appended_prompt_example_text = build_prompt_text(cleaned_example_text)\n",
    "    appended_prompt_example_text += ' 긍정' if example_label == 1 else ' 부정'\n",
    "    prompt_text += appended_prompt_example_text\n",
    "    \n",
    "print(prompt_text)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe936c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:00<00:00,  6.07s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "real_labels = []\n",
    "pred_tokens = []\n",
    "\n",
    "total_len = len(test_data[['document','label']].values)\n",
    "\n",
    "for i, (test_sent, test_label) in tqdm(enumerate(test_data[['document','label']].values), total=total_len):\n",
    "    prompt_text = ''\n",
    "\n",
    "    for ex in train_fewshot_samples[i]:\n",
    "        example_text, example_label = ex\n",
    "        cleaned_example_text = clean_text(example_text)\n",
    "        appended_prompt_example_text = build_prompt_text(cleaned_example_text)\n",
    "        appended_prompt_example_text += ' 긍정' if example_label == 1 else ' 부정' + '\\n'\n",
    "        prompt_text += appended_prompt_example_text\n",
    "\n",
    "    cleaned_sent = clean_text(test_sent)\n",
    "    appended_prompt_sent = build_prompt_text(cleaned_sent)\n",
    "\n",
    "    prompt_text += appended_prompt_sent\n",
    "\n",
    "    tokens = tokenizer(prompt_text, return_tensors=\"pt\").to(DEVICE)\n",
    "    token_ids, attn_mask = tokens.input_ids, tokens.attention_mask\n",
    "    gen_tokens = model.generate(input_ids=token_ids, attention_mask=attn_mask,\n",
    "                                    max_new_tokens=1, pad_token_id=0)\n",
    "    pred = tokenizer.batch_decode(gen_tokens[:, -1])[0].strip()\n",
    "\n",
    "    pred_tokens.append(pred)\n",
    "    real_labels.append('긍정' if test_label == 1 else '부정')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2337c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71\n"
     ]
    }
   ],
   "source": [
    "accuracy_match = [p == t for p, t in zip(pred_tokens, real_labels)]\n",
    "accuracy = len([m for m in accuracy_match if m]) / len(real_labels)\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca_env",
   "language": "python",
   "name": "alpaca_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
